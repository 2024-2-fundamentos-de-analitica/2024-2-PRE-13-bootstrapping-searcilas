{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\juanp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\juanp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\juanp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports\n",
    "#\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt  #  type: ignore\n",
    "import numpy as np  #  type: ignore\n",
    "import pandas as pd  #  type: ignore\n",
    "from sklearn.datasets import make_regression  #  type: ignore\n",
    "from sklearn.linear_model import LinearRegression  #  type: ignore\n",
    "from sklearn.neighbors import KernelDensity  #  type: ignore\n",
    "from tqdm import tqdm  #  type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:02<00:00, 362.87it/s]\n",
      "100%|██████████| 999/999 [00:02<00:00, 358.86it/s]\n",
      "100%|██████████| 999/999 [00:02<00:00, 364.82it/s]\n",
      "100%|██████████| 999/999 [00:02<00:00, 375.39it/s]\n",
      "100%|██████████| 999/999 [00:02<00:00, 368.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Parte 1: Generación de la simulación para análisis\n",
    "#\n",
    "def run_simulation(n_runs):\n",
    "\n",
    "    #\n",
    "    # Directorio de resultados\n",
    "    def create_results_folder():\n",
    "\n",
    "        if not os.path.exists(\"../files/results\"):\n",
    "            os.makedirs(\"../files/results\")\n",
    "\n",
    "    #\n",
    "    # Data generation\n",
    "    def generate_data():\n",
    "\n",
    "        X, y = make_regression(\n",
    "            n_samples=100,\n",
    "            n_features=3,\n",
    "            noise=0.1,\n",
    "            random_state=42,\n",
    "        )\n",
    "        df = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\"])\n",
    "        df[\"dummy1\"] = np.random.normal(0, 1, 100)\n",
    "        df[\"dummy2\"] = np.random.normal(0, 1, 100)\n",
    "        df[\"y\"] = y\n",
    "\n",
    "        return df\n",
    "\n",
    "    #\n",
    "    # Parameters estimation\n",
    "    def get_model_params(df):\n",
    "\n",
    "        X = df[[\"x1\", \"x2\", \"x3\", \"dummy1\", \"dummy2\"]]\n",
    "        y = df[\"y\"]\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        model = model.fit(X, y)\n",
    "        return {\n",
    "            \"x1\": model.coef_[0],\n",
    "            \"x2\": model.coef_[1],\n",
    "            \"x3\": model.coef_[2],\n",
    "            \"dummy1\": model.coef_[3],\n",
    "            \"dummy2\": model.coef_[4],\n",
    "            \"intercept\": model.intercept_,\n",
    "        }\n",
    "\n",
    "    def run_experiment(df, variable, n_runs):\n",
    "        #\n",
    "        # El primer experimento contiene los parametros del modelo\n",
    "        # sin permutar\n",
    "        results = []\n",
    "        params = get_model_params(df)\n",
    "        result = {\"variable\": variable, \"run\": 0, \"value\": params[variable]}\n",
    "        results.append(result)\n",
    "\n",
    "        for i_run in tqdm(range(1, n_runs)):\n",
    "            #\n",
    "            # Permuta la columna de interes y estima nuevamente\n",
    "            # los parametros del modelo\n",
    "            permuted_df = df.copy()\n",
    "            permuted_df[variable] = np.random.permutation(permuted_df[variable].values)\n",
    "            params = get_model_params(permuted_df)\n",
    "            result = {\"variable\": variable, \"run\": i_run, \"value\": params[variable]}\n",
    "            results.append(result)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def run_experiments(df, n_runs):\n",
    "        df = generate_data()\n",
    "        variables = [\"x1\", \"x2\", \"x3\", \"dummy1\", \"dummy2\"]\n",
    "        results = pd.concat(\n",
    "            [run_experiment(df, variable, n_runs) for variable in variables]\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    #\n",
    "    # Simulation\n",
    "    create_results_folder()\n",
    "    df = generate_data()\n",
    "    experiments = run_experiments(df, n_runs)\n",
    "    experiments[\"run\"] = experiments[\"run\"].astype(int)\n",
    "    experiments.to_csv(\"../files/results/experiments.csv\", index=False)\n",
    "\n",
    "\n",
    "#\n",
    "# Ejecuta la simulacion\n",
    "run_simulation(n_runs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generación de estadísticas por cada variable\n",
    "#\n",
    "def compute_stats():\n",
    "\n",
    "    experiments = pd.read_csv(\"../files/results/experiments.csv\")\n",
    "\n",
    "    #\n",
    "    # Extrae el coeficiente estimado para cada variable con el dataset\n",
    "    # original\n",
    "    current_values = experiments.loc[experiments[\"run\"] == 0].copy()\n",
    "    current_values = current_values.drop(columns=[\"run\"])\n",
    "    current_values = current_values.rename(columns={\"value\": \"original\"})\n",
    "    current_values = current_values.set_index(\"variable\")\n",
    "\n",
    "    #\n",
    "    # Calcula los estadísticos descriptivos para cada variable\n",
    "    stats = experiments[[\"variable\", \"value\"]].groupby([\"variable\"]).describe()\n",
    "    stats.columns = stats.columns.droplevel(0)\n",
    "\n",
    "    #\n",
    "    # Agrega el valor original\n",
    "    stats = stats.join(current_values, on=\"variable\")\n",
    "\n",
    "    #\n",
    "    # Genera el reporte\n",
    "    with open(\"../files/results/stats.txt\", \"w\") as file:\n",
    "        file.write(stats.to_string())\n",
    "    stats.to_csv(\"../files/results/stats.csv\")\n",
    "\n",
    "\n",
    "compute_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
